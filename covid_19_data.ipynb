{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "\n",
    "# for geocoding stuff\n",
    "import geopandas as gpd\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./data/\"\n",
    "input_dir = \"./csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob(input_dir+'*.{}'.format(extension))]\n",
    "\n",
    "# %% combine em up\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "combined_csv.to_csv(output_dir + \"covid_19_raw.csv\", index=False, encoding='utf-8-sig') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopy.geocoders.options.default_timeout = 30\n",
    "locator = Nominatim(user_agent=\"mesur.io\")\n",
    "geocode = RateLimiter(locator.geocode, min_delay_seconds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do a little data cleanup\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].str.strip()\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].replace('Korea, South', 'South Korea')\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].replace('Republic of Korea', 'South Korea')\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].replace('Iran (Islamic Republic of)', 'Iran')\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].replace('Mainland China', 'China')\n",
    "\n",
    "combined_csv['Country_Region'] = combined_csv['Country_Region'].str.strip()\n",
    "combined_csv['Country_Region'] = combined_csv['Country_Region'].replace('Korea, South', 'South Korea')\n",
    "combined_csv['Country_Region'] = combined_csv['Country_Region'].replace('Republic of Korea', 'South Korea')\n",
    "combined_csv['Country_Region'] = combined_csv['Country_Region'].replace('Iran (Islamic Republic of)', 'Iran')\n",
    "combined_csv['Country_Region'] = combined_csv['Country_Region'].replace('Mainland China', 'China')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined_csv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = combined.groupby(['Country/Region', 'Province/State'])['Latitude', 'Longitude'].mean().reset_index()\n",
    "locations.columns = ['Country/Region', 'Province/State', 'Latitude_Lookup', 'Longitude_Lookup']\n",
    "\n",
    "combined = pd.merge(left=combined, right=locations, left_on=['Country/Region', 'Province/State'], right_on=['Country/Region', 'Province/State'], how='left')\n",
    "combined['Latitude'] = combined['Latitude'].fillna(combined['Latitude_Lookup'])\n",
    "combined['Longitude'] = combined['Longitude'].fillna(combined['Longitude_Lookup'])\n",
    "del combined['Latitude_Lookup'] \n",
    "del combined['Longitude_Lookup'] \n",
    "\n",
    "locations2 = combined.groupby(['Country/Region', 'Province/State'])['Lat', 'Long_'].mean().reset_index()\n",
    "locations2.columns = ['Country/Region', 'Province/State', 'Latitude_Lookup', 'Longitude_Lookup']\n",
    "\n",
    "combined = pd.merge(left=combined, right=locations2, left_on=['Country/Region', 'Province/State'], right_on=['Country/Region', 'Province/State'], how='left')\n",
    "combined['Latitude'] = combined['Latitude'].fillna(combined['Latitude_Lookup'])\n",
    "combined['Longitude'] = combined['Longitude'].fillna(combined['Longitude_Lookup'])\n",
    "del combined['Latitude_Lookup'] \n",
    "del combined['Longitude_Lookup'] \n",
    "\n",
    "combined['Last Update'] = combined['Last Update'].fillna(combined['Last_Update'])\n",
    "combined['Country/Region'] = combined['Country/Region'].fillna(combined['Country_Region'])\n",
    "combined['Province/State'] = combined['Province/State'].fillna(combined['Province_State'])\n",
    "combined['Province/State'] = combined['Province/State'].fillna(combined['Country/Region'])\n",
    "combined['Confirmed'] = combined['Confirmed'].fillna(0)\n",
    "combined['Deaths'] = combined['Deaths'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Last Update'] = pd.to_datetime(combined['Last Update'])\n",
    "combined = combined.sort_values('Last Update').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Geo_Input'] = combined['Province/State']+', '+combined['Country/Region'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_located = combined[combined['Latitude'].isna()]\n",
    "non_located = non_located[non_located['Province/State'] != 'Cruise Ship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_inputs = non_located['Geo_Input'].unique()\n",
    "combined['Location_Key_Raw'] = combined.apply(lambda x: (x.Latitude, x.Longitude), axis = 1)\n",
    "#for testing you may want to trim this down a bit\n",
    "#geo_inputs = geo_inputs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode():\n",
    "    print('Geocoding for: ', len(geo_inputs), 'locations')\n",
    "    #use progress_apply() for interactive progress\n",
    "    d = dict(zip(geo_inputs, pd.Series(geo_inputs).apply(geocode).apply(lambda x: (x.latitude if pd.notnull(x.latitude) else x.latitude, \n",
    "                                                                                   x.longitude if pd.notnull(x.longitude) else x.longitude) if pd.notnull(x) else x)\n",
    "                )\n",
    "            )\n",
    "    pd.DataFrame.from_dict(d, orient=\"index\").to_csv('./reference/geoloc_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('./reference/geoloc_dict.json', index_col=0).to_dict(\"split\")\n",
    "d = dict(zip(d[\"index\"], d[\"data\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Location_Key'] = combined['Geo_Input'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Location_Key'] = combined['Location_Key'].fillna(combined['Location_Key_Raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Latitude'] = combined.loc[combined['Latitude'].isna(), 'Location_Key'].apply(lambda x: x[0])\n",
    "combined['Longitude'] = combined.loc[combined['Longitude'].isna(), 'Location_Key'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's do a recovery est\n",
    "# first need the day of outbreak\n",
    "combined = combined.sort_values('Last Update').reset_index(drop=True)\n",
    "combined['Day'] = combined.groupby('Country/Region').cumcount()\n",
    "combined['DayLoc'] = combined.groupby(['Latitude','Longitude']).cumcount()\n",
    "combined['DayCountry'] = combined.groupby('Country/Region').cumcount()\n",
    "combined['DayCountryProvince'] = combined.groupby('Geo_Input').cumcount()\n",
    "\n",
    "combined['UnknownActive'] = combined['Confirmed'] - combined['Deaths']\n",
    "combined['RecoveredEst'] = np.floor(combined['UnknownActive'] * .14)\n",
    "combined['Recovered'] = combined['Recovered'].fillna(0)\n",
    "#hold on this for now, there is a formula that is curve based for this\n",
    "#combined.loc[combined['Recovered'] == 0, 'Recovered'] = combined['RecoveredEst']\n",
    "combined['Active'] = combined['UnknownActive'] - combined['Recovered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a little reording and subselection\n",
    "combined_csv = combined[['Last Update','Latitude','Longitude','Country/Region','Province/State','FIPS','Admin2',\n",
    "                         'Confirmed','Deaths','Recovered','UnknownActive', 'Active',\n",
    "                         'Day','DayLoc','DayCountry','DayCountryProvince']]\n",
    "combined_csv = combined_csv.sort_values(['Last Update','Latitude','Longitude','Country/Region','Province/State'])\n",
    "#combined_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv.to_csv(output_dir + \"combined.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_cases = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/web-data/data/cases.csv')\n",
    "web_cases_state = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/web-data/data/cases_state.csv')\n",
    "web_cases_country = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/web-data/data/cases_country.csv')\n",
    "web_cases_time = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/web-data/data/cases_time.csv')\n",
    "\n",
    "web_cases.to_csv(output_dir + \"web_cases.csv\", index=False, encoding='utf-8-sig')\n",
    "web_cases_state.to_csv(output_dir + \"web_cases_state.csv\", index=False, encoding='utf-8-sig')\n",
    "web_cases_country.to_csv(output_dir + \"web_cases_country.csv\", index=False, encoding='utf-8-sig')\n",
    "web_cases_time.to_csv(output_dir + \"web_cases_time.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_csv.copy()\n",
    "df['Last Update'] = pd.to_datetime(df['Last Update']).dt.date \n",
    "\n",
    "def firsti(Series, offset):\n",
    "    return Series.first(offset)\n",
    "\n",
    "df = df.groupby(by=['Last Update', 'Country/Region'])[\n",
    "    #'Last Update', 'Country/Region',\n",
    "    'Confirmed', 'Deaths', 'Recovered'].sum().reset_index()\n",
    "df = df.sort_values('Last Update', ascending=True).reset_index()\n",
    "df['Active Cases'] = df['Confirmed'] - df['Recovered'] - df['Deaths']\n",
    "df['Cases'] = df['Confirmed'] - df['Recovered'] \n",
    "df['Death Rate'] = df['Deaths'] / df['Confirmed']\n",
    "df['Recovery Rate'] = df['Recovered'] / df['Confirmed']\n",
    "df['New Deaths'] = df['Deaths'] - df['Deaths'].shift()\n",
    "df['New Recovered'] = df['Recovered'] - df['Recovered'].shift()\n",
    "df['New Cases'] = df['Confirmed'] - df['Confirmed'].shift()\n",
    "df['New Case Rate'] = df['New Cases'].pct_change()\n",
    "df['New Death Rate'] = df['New Deaths'].pct_change()\n",
    "df['Last Update'] = pd.to_datetime(df['Last Update'])\n",
    "df['Date'] = pd.DatetimeIndex(df['Last Update']).astype ( np.int64 )/1000000\n",
    "df['Day'] = df.groupby('Country/Region').cumcount()\n",
    "df = df.dropna().reset_index()\n",
    "\n",
    "df.to_csv(output_dir + \"covid_19_by_date_and_country.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallDf = df.copy().groupby('Last Update').agg({\n",
    "    'Confirmed':'sum',\n",
    "    'Deaths':'sum',\n",
    "    'Recovered':'sum'\n",
    "    }).reset_index()\n",
    "overallDf = overallDf.sort_values('Last Update', ascending=True)\n",
    "overallDf['Active Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] - overallDf['Deaths']\n",
    "overallDf['Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] \n",
    "overallDf['Death Rate'] = overallDf['Deaths'] / overallDf['Confirmed']\n",
    "overallDf['Recovery Rate'] = overallDf['Recovered'] / overallDf['Confirmed']\n",
    "overallDf['New Deaths'] = overallDf['Deaths'] - overallDf['Deaths'].shift()\n",
    "overallDf['New Recovered'] = overallDf['Recovered'] - overallDf['Recovered'].shift()\n",
    "overallDf['New Cases'] = overallDf['Confirmed'] - overallDf['Confirmed'].shift()\n",
    "overallDf['New Case Rate'] = overallDf['New Cases'].pct_change()\n",
    "overallDf['New Death Rate'] = overallDf['New Deaths'].pct_change()\n",
    "overallDf['Date'] = pd.DatetimeIndex(overallDf['Last Update']).astype ( np.int64 )/1000000\n",
    "overallDf = overallDf.dropna().reset_index()\n",
    "\n",
    "overallDf.to_csv(output_dir + \"covid_19_by_date.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallDf = df.copy().groupby('Day').agg({\n",
    "    'Confirmed':'sum',\n",
    "    'Deaths':'sum',\n",
    "    'Recovered':'sum'\n",
    "    }).reset_index()\n",
    "overallDf = overallDf.sort_values('Day', ascending=True)\n",
    "overallDf['Active Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] - overallDf['Deaths']\n",
    "overallDf['Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] \n",
    "overallDf['Death Rate'] = overallDf['Deaths'] / overallDf['Confirmed']\n",
    "overallDf['Recovery Rate'] = overallDf['Recovered'] / overallDf['Confirmed']\n",
    "overallDf['New Deaths'] = overallDf['Deaths'] - overallDf['Deaths'].shift()\n",
    "overallDf['New Recovered'] = overallDf['Recovered'] - overallDf['Recovered'].shift()\n",
    "overallDf['New Cases'] = overallDf['Confirmed'] - overallDf['Confirmed'].shift()\n",
    "overallDf['New Case Rate'] = overallDf['New Cases'].pct_change()\n",
    "overallDf['New Death Rate'] = overallDf['New Deaths'].pct_change()\n",
    "overallDf = overallDf.dropna().reset_index()\n",
    "\n",
    "overallDf.to_csv(output_dir + \"covid_19_by_day.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallDf = df.copy().groupby(by=['Country/Region','Day']).agg({\n",
    "    'Confirmed':'sum',\n",
    "    'Deaths':'sum',\n",
    "    'Recovered':'sum'\n",
    "    }).reset_index()\n",
    "overallDf = overallDf.sort_values('Day', ascending=True)\n",
    "overallDf['Active Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] - overallDf['Deaths']\n",
    "overallDf['Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] \n",
    "overallDf['Death Rate'] = overallDf['Deaths'] / overallDf['Confirmed']\n",
    "overallDf['Recovery Rate'] = overallDf['Recovered'] / overallDf['Confirmed']\n",
    "overallDf['New Deaths'] = overallDf['Deaths'] - overallDf['Deaths'].shift()\n",
    "overallDf['New Recovered'] = overallDf['Recovered'] - overallDf['Recovered'].shift()\n",
    "overallDf['New Cases'] = overallDf['Confirmed'] - overallDf['Confirmed'].shift()\n",
    "overallDf['New Case Rate'] = overallDf['New Cases'].pct_change()\n",
    "overallDf['New Death Rate'] = overallDf['New Deaths'].pct_change()\n",
    "overallDf = overallDf.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#john's hopkins raw files\n",
    "ts_deaths = pd.read_csv('csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\n",
    "ts_confirmed = pd.read_csv('csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n",
    "#new recovered tracking has now been dropped :(\n",
    "ts_recovered = pd.read_csv('csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv')\n",
    "\n",
    "# let's unpivot that nasty excel style stuff\n",
    "ts_deaths = pd.melt(ts_deaths, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name='Date', value_name='Observation')\n",
    "ts_deaths['Observation Type'] = 'Death'\n",
    "ts_confirmed = pd.melt(ts_confirmed, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name='Date', value_name='Observation')\n",
    "ts_confirmed['Observation Type'] = 'Confirmed'\n",
    "ts_recovered = pd.melt(ts_recovered, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name='Date', value_name='Observation')\n",
    "ts_recovered['Observation Type'] = 'Recovered'\n",
    "\n",
    "ts_deaths['Date'] = pd.to_datetime(ts_deaths['Date'])\n",
    "ts_confirmed['Date'] = pd.to_datetime(ts_confirmed['Date'])\n",
    "ts_recovered['Date'] = pd.to_datetime(ts_recovered['Date'])\n",
    "\n",
    "#and concat into one nice set\n",
    "covid_19_ts = ts_deaths.copy()\n",
    "covid_19_ts = covid_19_ts.append(ts_recovered)\n",
    "covid_19_ts = covid_19_ts.append(ts_confirmed)\n",
    "covid_19_ts = covid_19_ts.sort_values(['Country/Region', 'Province/State', 'Date']).reset_index(drop=True)\n",
    "\n",
    "#now drop 0 values\n",
    "covid_19_ts = covid_19_ts[covid_19_ts['Observation'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallDf.to_csv(output_dir + \"covid_19_by_date_and_country.csv\", index=False, encoding='utf-8-sig')\n",
    "covid_19_ts.to_csv(output_dir + \"covid_19_ts.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display for debug\n",
    "#display(covid_19_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('miniconda3': virtualenv)",
   "language": "python",
   "name": "python37664bitminiconda3virtualenve3b6ad2979204d799798e97f12a748c5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
