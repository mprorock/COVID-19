{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./data/\"\n",
    "input_dir = \"./csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob(input_dir+'*.{}'.format(extension))]\n",
    "\n",
    "# %% combine em up\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "combined_csv.to_csv(output_dir + \"covid_19.csv\", index=False, encoding='utf-8-sig') \n",
    "\n",
    "# let's do a little data cleanup\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].str.strip()\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].replace('Korea, South', 'South Korea')\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].replace('Republic of Korea', 'South Korea')\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].replace('Iran (Islamic Republic of)', 'Iran')\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].replace('Mainland China', 'China')\n",
    "\n",
    "combined_csv.to_csv(output_dir + \"combined.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "us_state_abbrev = {\n",
    "        'Alabama': 'AL',\n",
    "        'Alaska': 'AK',\n",
    "        'Arizona': 'AZ',\n",
    "        'Arkansas': 'AR',\n",
    "        'California': 'CA',\n",
    "        'Colorado': 'CO',\n",
    "        'Connecticut': 'CT',\n",
    "        'Delaware': 'DE',\n",
    "        'District of Columbia': 'D.C.',\n",
    "        'Florida': 'FL',\n",
    "        'Georgia': 'GA',\n",
    "        'Hawaii': 'HI',\n",
    "        'Idaho': 'ID',\n",
    "        'Illinois': 'IL',\n",
    "        'Indiana': 'IN',\n",
    "        'Iowa': 'IA',\n",
    "        'Kansas': 'KS',\n",
    "        'Kentucky': 'KY',\n",
    "        'Louisiana': 'LA',\n",
    "        'Maine': 'ME',\n",
    "        'Maryland': 'MD',\n",
    "        'Massachusetts': 'MA',\n",
    "        'Michigan': 'MI',\n",
    "        'Minnesota': 'MN',\n",
    "        'Mississippi': 'MS',\n",
    "        'Missouri': 'MO',\n",
    "        'Montana': 'MT',\n",
    "        'Nebraska': 'NE',\n",
    "        'Nevada': 'NV',\n",
    "        'New Hampshire': 'NH',\n",
    "        'New Jersey': 'NJ',\n",
    "        'New Mexico': 'NM',\n",
    "        'New York': 'NY',\n",
    "        'North Carolina': 'NC',\n",
    "        'North Dakota': 'ND',\n",
    "        'Northern Mariana Islands':'MP',\n",
    "        'Ohio': 'OH',\n",
    "        'Oklahoma': 'OK',\n",
    "        'Oregon': 'OR',\n",
    "        'Palau': 'PW',\n",
    "        'Pennsylvania': 'PA',\n",
    "        'Puerto Rico': 'PR',\n",
    "        'Rhode Island': 'RI',\n",
    "        'South Carolina': 'SC',\n",
    "        'South Dakota': 'SD',\n",
    "        'Tennessee': 'TN',\n",
    "        'Texas': 'TX',\n",
    "        'Utah': 'UT',\n",
    "        'Vermont': 'VT',\n",
    "        'Virgin Islands': 'VI',\n",
    "        'Virginia': 'VA',\n",
    "        'Washington': 'WA',\n",
    "        'West Virginia': 'WV',\n",
    "        'Wisconsin': 'WI',\n",
    "        'Wyoming': 'WY',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_csv.copy()\n",
    "df['Last Update'] = pd.to_datetime(df['Last Update']).dt.date \n",
    "\n",
    "def firsti(Series, offset):\n",
    "    return Series.first(offset)\n",
    "\n",
    "df = df.groupby(by=['Last Update', 'Country/Region'])[\n",
    "    #'Last Update', 'Country/Region',\n",
    "    'Confirmed', 'Deaths', 'Recovered'].sum().reset_index()\n",
    "df = df.sort_values('Last Update', ascending=True).reset_index()\n",
    "df['Active Cases'] = df['Confirmed'] - df['Recovered'] - df['Deaths']\n",
    "df['Cases'] = df['Confirmed'] - df['Recovered'] \n",
    "df['Death Rate'] = df['Deaths'] / df['Confirmed']\n",
    "df['Recovery Rate'] = df['Recovered'] / df['Confirmed']\n",
    "df['New Deaths'] = df['Deaths'] - df['Deaths'].shift()\n",
    "df['New Recovered'] = df['Recovered'] - df['Recovered'].shift()\n",
    "df['New Cases'] = df['Confirmed'] - df['Confirmed'].shift()\n",
    "df['New Case Rate'] = df['New Cases'].pct_change()\n",
    "df['New Death Rate'] = df['New Deaths'].pct_change()\n",
    "df['Last Update'] = pd.to_datetime(df['Last Update'])\n",
    "df['Date'] = pd.DatetimeIndex(df['Last Update']).astype ( np.int64 )/1000000\n",
    "df['Day'] = df.groupby('Country/Region').cumcount()\n",
    "df = df.dropna().reset_index()\n",
    "\n",
    "df.to_csv(output_dir + \"covid_19_by_date_and_country.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallDf = df.copy().groupby('Last Update').agg({\n",
    "    'Confirmed':'sum',\n",
    "    'Deaths':'sum',\n",
    "    'Recovered':'sum'\n",
    "    }).reset_index()\n",
    "overallDf = overallDf.sort_values('Last Update', ascending=True)\n",
    "overallDf['Active Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] - overallDf['Deaths']\n",
    "overallDf['Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] \n",
    "overallDf['Death Rate'] = overallDf['Deaths'] / overallDf['Confirmed']\n",
    "overallDf['Recovery Rate'] = overallDf['Recovered'] / overallDf['Confirmed']\n",
    "overallDf['New Deaths'] = overallDf['Deaths'] - overallDf['Deaths'].shift()\n",
    "overallDf['New Recovered'] = overallDf['Recovered'] - overallDf['Recovered'].shift()\n",
    "overallDf['New Cases'] = overallDf['Confirmed'] - overallDf['Confirmed'].shift()\n",
    "overallDf['New Case Rate'] = overallDf['New Cases'].pct_change()\n",
    "overallDf['New Death Rate'] = overallDf['New Deaths'].pct_change()\n",
    "overallDf['Date'] = pd.DatetimeIndex(overallDf['Last Update']).astype ( np.int64 )/1000000\n",
    "overallDf = overallDf.dropna().reset_index()\n",
    "\n",
    "overallDf.to_csv(output_dir + \"covid_19_by_date.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallDf = df.copy().groupby('Day').agg({\n",
    "    'Confirmed':'sum',\n",
    "    'Deaths':'sum',\n",
    "    'Recovered':'sum'\n",
    "    }).reset_index()\n",
    "overallDf = overallDf.sort_values('Day', ascending=True)\n",
    "overallDf['Active Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] - overallDf['Deaths']\n",
    "overallDf['Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] \n",
    "overallDf['Death Rate'] = overallDf['Deaths'] / overallDf['Confirmed']\n",
    "overallDf['Recovery Rate'] = overallDf['Recovered'] / overallDf['Confirmed']\n",
    "overallDf['New Deaths'] = overallDf['Deaths'] - overallDf['Deaths'].shift()\n",
    "overallDf['New Recovered'] = overallDf['Recovered'] - overallDf['Recovered'].shift()\n",
    "overallDf['New Cases'] = overallDf['Confirmed'] - overallDf['Confirmed'].shift()\n",
    "overallDf['New Case Rate'] = overallDf['New Cases'].pct_change()\n",
    "overallDf['New Death Rate'] = overallDf['New Deaths'].pct_change()\n",
    "overallDf = overallDf.dropna().reset_index()\n",
    "\n",
    "overallDf.to_csv(output_dir + \"covid_19_by_day.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallDf = df.copy().groupby(by=['Country/Region','Day']).agg({\n",
    "    'Confirmed':'sum',\n",
    "    'Deaths':'sum',\n",
    "    'Recovered':'sum'\n",
    "    }).reset_index()\n",
    "overallDf = overallDf.sort_values('Day', ascending=True)\n",
    "overallDf['Active Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] - overallDf['Deaths']\n",
    "overallDf['Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] \n",
    "overallDf['Death Rate'] = overallDf['Deaths'] / overallDf['Confirmed']\n",
    "overallDf['Recovery Rate'] = overallDf['Recovered'] / overallDf['Confirmed']\n",
    "overallDf['New Deaths'] = overallDf['Deaths'] - overallDf['Deaths'].shift()\n",
    "overallDf['New Recovered'] = overallDf['Recovered'] - overallDf['Recovered'].shift()\n",
    "overallDf['New Cases'] = overallDf['Confirmed'] - overallDf['Confirmed'].shift()\n",
    "overallDf['New Case Rate'] = overallDf['New Cases'].pct_change()\n",
    "overallDf['New Death Rate'] = overallDf['New Deaths'].pct_change()\n",
    "overallDf = overallDf.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#john's hopkins raw files\n",
    "ts_deaths = pd.read_csv('csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv')\n",
    "ts_recovered = pd.read_csv('csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv')\n",
    "ts_confirmed = pd.read_csv('csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv')\n",
    "\n",
    "# let's unpivot that nasty excel style stuff\n",
    "ts_deaths = pd.melt(ts_deaths, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name='Date', value_name='Observation')\n",
    "ts_deaths['Observation Type'] = 'Death'\n",
    "ts_recovered = pd.melt(ts_recovered, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name='Date', value_name='Observation')\n",
    "ts_recovered['Observation Type'] = 'Recovered'\n",
    "ts_confirmed = pd.melt(ts_confirmed, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name='Date', value_name='Observation')\n",
    "ts_confirmed['Observation Type'] = 'Confirmed'\n",
    "\n",
    "ts_deaths['Date'] = pd.to_datetime(ts_deaths['Date'])\n",
    "ts_recovered['Date'] = pd.to_datetime(ts_recovered['Date'])\n",
    "ts_confirmed['Date'] = pd.to_datetime(ts_confirmed['Date'])\n",
    "\n",
    "#and concat into one nice set\n",
    "covid_19_ts = ts_deaths.copy()\n",
    "covid_19_ts = covid_19_ts.append(ts_recovered)\n",
    "covid_19_ts = covid_19_ts.append(ts_confirmed)\n",
    "covid_19_ts = covid_19_ts.sort_values(['Country/Region', 'Province/State', 'Date']).reset_index(drop=True)\n",
    "\n",
    "#now drop 0 values\n",
    "covid_19_ts = covid_19_ts[covid_19_ts['Observation'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallDf.to_csv(output_dir + \"covid_19_by_date_and_country.csv\", index=False, encoding='utf-8-sig')\n",
    "covid_19_ts.to_csv(output_dir + \"covid_19_ts.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display for debug\n",
    "#display(covid_19_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run any JH combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_19_by_country_and_day_of_outbreak = pd.read_csv(output_dir + 'covid_19_by_date_and_country.csv')\n",
    "covid_19_by_date = pd.read_csv(output_dir + 'covid_19_by_date.csv')\n",
    "covid_19_by_day = pd.read_csv(output_dir + 'covid_19_by_day.csv')\n",
    "covid_19_overall = pd.read_csv(output_dir + 'covid_19.csv')\n",
    "covid_19_ts = pd.read_csv(output_dir + 'covid_19_ts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_19_ts['Date'] = pd.to_datetime(covid_19_ts['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = covid_19_ts.copy()\n",
    "#if you just want to include some, exclude others, see line below:\n",
    "#ts_df = covid_19_ts[covid_19_ts['Country/Region'] != 'US'].copy()\n",
    "ts_df = ts_df.drop('Province/State', axis=1)\n",
    "ts_df = ts_df.sort_values(['Country/Region', 'Date'])\n",
    "\n",
    "covid_19_national_observations = ts_df.groupby(['Date', 'Country/Region', 'Observation Type'])['Observation'].sum().reset_index()\n",
    "covid_19_national_observations = covid_19_national_observations.pivot_table(columns='Observation Type', index=['Date', 'Country/Region'], values='Observation').reset_index().rename_axis(None, axis=1).fillna(0)\n",
    "\n",
    "#let's get a copy for post infection as well\n",
    "covid_19_infected_observations = covid_19_national_observations.copy()\n",
    "covid_19_infected_observations = covid_19_infected_observations[covid_19_infected_observations['Confirmed'] >= 20].fillna(0)\n",
    "\n",
    "#on to key values for reporting\n",
    "covid_19_national_observations['Day'] = covid_19_national_observations.groupby('Country/Region')['Confirmed'].cumcount()\n",
    "covid_19_national_observations['Day'] = covid_19_national_observations.groupby('Country/Region')['Confirmed'].fillna(method='bfill')\n",
    "\n",
    "covid_19_national_observations['Active Cases'] = covid_19_national_observations['Confirmed'] - covid_19_national_observations['Recovered']  - covid_19_national_observations['Death'] \n",
    "\n",
    "covid_19_national_observations['Likely Cases 1pct'] = covid_19_national_observations['Death'] * 100\n",
    "covid_19_national_observations['Likely Cases 1.8pct'] = covid_19_national_observations['Death'] * 180\n",
    "covid_19_national_observations['Likely Cases 3.5pct'] = covid_19_national_observations['Death'] * 350\n",
    "\n",
    "covid_19_national_observations['Death Rate'] = np.round(covid_19_national_observations['Death'] / covid_19_national_observations['Confirmed'],3)\n",
    "covid_19_national_observations['Death Change Rate'] = covid_19_national_observations.groupby('Country/Region')['Death'].pct_change()\n",
    "covid_19_national_observations['Recovery Change Rate'] = covid_19_national_observations.groupby('Country/Region')['Recovered'].pct_change()\n",
    "covid_19_national_observations['Confirmed Change Rate'] = covid_19_national_observations.groupby('Country/Region')['Confirmed'].pct_change()\n",
    "\n",
    "#now for same values on limited set\n",
    "covid_19_infected_observations['Day'] = covid_19_infected_observations.groupby('Country/Region', squeeze=True).cumcount()\n",
    "\n",
    "covid_19_infected_observations['Active Cases'] = covid_19_infected_observations['Confirmed'] - covid_19_infected_observations['Recovered']  - covid_19_infected_observations['Death'] \n",
    "\n",
    "covid_19_infected_observations['Likely Cases 1pct'] = covid_19_infected_observations['Death'] * 100\n",
    "covid_19_infected_observations['Likely Cases 1.8pct'] = covid_19_infected_observations['Death'] * 180\n",
    "covid_19_infected_observations['Likely Cases 3.5pct'] = covid_19_infected_observations['Death'] * 350\n",
    "\n",
    "covid_19_infected_observations['Death Rate'] = np.round(covid_19_infected_observations['Death'] / covid_19_infected_observations['Confirmed'],3)\n",
    "covid_19_infected_observations['Death Change Rate'] = covid_19_infected_observations.groupby('Country/Region')['Death'].pct_change()\n",
    "covid_19_infected_observations['Recovery Change Rate'] = covid_19_infected_observations.groupby('Country/Region')['Recovered'].pct_change()\n",
    "covid_19_infected_observations['Confirmed Change Rate'] = covid_19_infected_observations.groupby('Country/Region')['Confirmed'].pct_change()\n",
    "\n",
    "covid_19_infected_observations['Case Bins'] = pd.qcut(covid_19_infected_observations['Active Cases'], 10)\n",
    "maxes = covid_19_infected_observations.groupby('Country/Region')['Day'].max().reset_index()\n",
    "maxes.columns = ['Country/Region', 'Max Day']\n",
    "covid_19_infected_observations = pd.merge(left=covid_19_infected_observations, right=maxes, left_on='Country/Region', right_on='Country/Region', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_19_national_observations.to_csv(output_dir + \"global/covid_19_national_observations.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "covid_19_infected_observations.to_csv(output_dir + \"global/covid_19_infected_observations.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covid_19_national_observations[covid_19_national_observations['Country/Region']=='Brazil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_totals = covid_19_national_observations.groupby(['Date']).sum().reset_index().copy()\n",
    "world_totals = world_totals.sort_values('Date')\n",
    "world_totals['Total Confirmed'] = world_totals['Confirmed'].rolling(1).sum().fillna(0)\n",
    "world_totals['Total Deaths'] = world_totals['Death'].rolling(1).sum().fillna(0)\n",
    "world_totals['Total Recovered'] = world_totals['Recovered'].rolling(1).sum().fillna(0)\n",
    "world_totals['Active Cases'] = world_totals['Total Confirmed'] - world_totals['Total Deaths'] - world_totals['Total Recovered']\n",
    "world_totals['Death Rate'] = np.round(world_totals['Total Deaths'] / world_totals['Total Confirmed'],3)\n",
    "world_totals['Death Change Rate'] = world_totals['Total Deaths'].pct_change()\n",
    "world_totals['Recovery Change Rate'] = world_totals['Total Recovered'].pct_change()\n",
    "world_totals['Confirmed Change Rate'] = world_totals['Total Confirmed'].pct_change()\n",
    "\n",
    "world_totals['Likely Cases C86'] = world_totals['Active Cases'] * 1.14\n",
    "world_totals['Likely Cases 1pct'] = world_totals['Total Deaths'] * 100\n",
    "world_totals['Likely Cases 1.8pct'] = world_totals['Total Deaths'] * 180\n",
    "world_totals['Likely Cases 3.5pct'] = world_totals['Total Deaths'] * 350\n",
    "\n",
    "world_totals.to_csv(output_dir + \"global/covid_19_world_totals.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country specific stuff below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitionByCountry(country):  \n",
    "    print('Processing data files for', country)\n",
    "    c = country.lower().replace(' ', '_')\n",
    "    c = c.replace('*', '').replace('(', '_').replace(')', '_')\n",
    "    os.makedirs(output_dir + 'countries/'+c, exist_ok=True)\n",
    "\n",
    "    df = covid_19_ts[covid_19_ts['Country/Region'] == country].copy()\n",
    "    df['Province/State'] = df['Province/State'].str.rsplit(',').str[-1].str.strip() \n",
    "    df['Province/State'] = df['Province/State'].replace(us_state_abbrev)\n",
    "\n",
    "    df = df.sort_values(['Province/State', 'Date'])\n",
    "    \n",
    "    if c == 'us':\n",
    "        print(df['Province/State'].unique())\n",
    "\n",
    "    cases = pd.DataFrame()\n",
    "    if df['Province/State'].count() == 0:\n",
    "        df['Province/State'] = country\n",
    "        cases = df.groupby(['Date', 'Observation Type'])['Observation'].sum().reset_index()\n",
    "        cases = cases.pivot_table(columns='Observation Type', index=['Date'], values='Observation').reset_index().rename_axis(None, axis=1)\n",
    "        cases['Province/State'] = country\n",
    "    else:\n",
    "        cases = df.groupby(['Date', 'Province/State', 'Observation Type'])['Observation'].sum().reset_index()\n",
    "        cases = cases.pivot_table(columns='Observation Type', index=['Date', 'Province/State'], values='Observation').reset_index().rename_axis(None, axis=1)\n",
    "    \n",
    "    # check if columns exist\n",
    "    if 'Death' not in cases.columns:\n",
    "        cases['Death'] = 0\n",
    "    if 'Confirmed' not in cases.columns:\n",
    "        cases['Death'] = 0\n",
    "    if 'Recovered' not in cases.columns:\n",
    "        cases['Recovered'] = 0\n",
    "    \n",
    "    totals = cases.groupby(['Date']).sum().reset_index().copy()\n",
    "    totals = totals.sort_values('Date')    \n",
    "    \n",
    "    totals['Total Confirmed'] = totals['Confirmed'].rolling(1).sum().fillna(0)\n",
    "    totals['Total Deaths'] = totals['Death'].rolling(1).sum().fillna(0)\n",
    "    totals['Total Recovered'] = totals['Recovered'].rolling(1).sum().fillna(0)\n",
    "    totals['Active Cases'] = totals['Total Confirmed'] - totals['Total Deaths'] - totals['Total Recovered']\n",
    "    totals['Death Rate'] = np.round(totals['Total Deaths'] / totals['Total Confirmed'], 3).fillna(0)\n",
    "    totals['Death Change Rate'] = np.round(totals['Total Deaths'].pct_change(), 3).fillna(0)\n",
    "    totals['Recovery Change Rate'] = np.round(totals['Total Recovered'].pct_change(), 3).fillna(0)\n",
    "    totals['Confirmed Change Rate'] = np.round(totals['Total Confirmed'].pct_change(), 3).fillna(0)\n",
    "    \n",
    "    totals['New Active Cases'] = totals['Active Cases'] - totals['Active Cases'].shift()\n",
    "    totals['New Active Cases PCT Change'] = totals['New Active Cases'].pct_change().fillna(0)\n",
    "\n",
    "    totals['New Cases'] = totals['Confirmed'] - totals['Confirmed'].shift()\n",
    "    totals['New Case PCT Change'] = totals['New Cases'].pct_change().fillna(0)\n",
    "\n",
    "    totals['New Deaths'] = totals['Death'] - totals['Death'].shift()\n",
    "    totals['New Death PCT Change'] = totals['New Deaths'].pct_change().fillna(0)\n",
    "    \n",
    "    totals['New Recovered'] = totals['Recovered'] - totals['Recovered'].shift()\n",
    "    totals['New Recovered PCT Change'] = totals['New Recovered'].pct_change().fillna(0)\n",
    "    \n",
    "    totals['Likely Cases C86'] = totals['Active Cases'] * 1.14\n",
    "    totals['Likely Cases 1pct'] = totals['Total Deaths'] * 100\n",
    "    totals['Likely Cases 1.8pct'] = totals['Total Deaths'] * 180\n",
    "    totals['Likely Cases 3.5pct'] = totals['Total Deaths'] * 350\n",
    "    \n",
    "    if df['Province/State'].count() <= 1:\n",
    "        cases['Total Confirmed'] = cases['Confirmed'].rolling(1).sum()\n",
    "        cases['Total Deaths'] = cases['Death'].rolling(1).sum()\n",
    "        cases['Total Recovered'] = cases['Recovered'].rolling(1).sum()\n",
    "    else:\n",
    "        cases['Total Confirmed'] = cases.groupby('Province/State')['Confirmed'].rolling(1).sum().reset_index(0,drop=True)\n",
    "        cases['Total Deaths'] = cases.groupby('Province/State')['Death'].rolling(1).sum().reset_index(0,drop=True)\n",
    "        cases['Total Recovered'] = cases.groupby('Province/State')['Recovered'].rolling(1).sum().reset_index(0,drop=True)\n",
    "    cases['Active Cases'] = totals['Total Confirmed'] - totals['Total Deaths'] - totals['Total Recovered']\n",
    "    cases['Death Rate'] = np.round(totals['Total Deaths'] / totals['Total Confirmed'],3)\n",
    "    cases['Death Change Rate'] = np.round(totals['Total Deaths'].pct_change(), 3)\n",
    "    cases['Recovery Change Rate'] = np.round(totals['Total Recovered'].pct_change(), 3)\n",
    "    cases['Confirmed Change Rate'] = np.round(totals['Total Confirmed'].pct_change(), 3)\n",
    "\n",
    "    \n",
    "    cases['Likely Cases 1pct'] = np.round(cases['Death'] * 100)\n",
    "    cases['Likely Cases 1.8pct'] = np.round(cases['Death'] * 180)\n",
    "    cases['Likely Cases 3.5pct'] = np.round(cases['Death'] * 350)\n",
    "    cases['Likely Cases C86'] = np.round(cases['Confirmed'] * 1.14)\n",
    "\n",
    "        \n",
    "    cases.to_csv(output_dir + 'countries/'+c+'/covid_19_'+c+'_cases.csv', index=False, encoding='utf-8-sig')\n",
    "    totals.to_csv(output_dir + 'countries/'+c+'/covid_19_'+c+'_totals.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data files for Afghanistan\n",
      "Processing data files for Albania\n",
      "Processing data files for Algeria\n",
      "Processing data files for Andorra\n",
      "Processing data files for Angola\n",
      "Processing data files for Antigua and Barbuda\n",
      "Processing data files for Argentina\n",
      "Processing data files for Armenia\n",
      "Processing data files for Australia\n",
      "Processing data files for Austria\n",
      "Processing data files for Azerbaijan\n",
      "Processing data files for Bahamas, The\n",
      "Processing data files for Bahrain\n",
      "Processing data files for Bangladesh\n",
      "Processing data files for Barbados\n",
      "Processing data files for Belarus\n",
      "Processing data files for Belgium\n",
      "Processing data files for Benin\n",
      "Processing data files for Bhutan\n",
      "Processing data files for Bolivia\n",
      "Processing data files for Bosnia and Herzegovina\n",
      "Processing data files for Brazil\n",
      "Processing data files for Brunei\n",
      "Processing data files for Bulgaria\n",
      "Processing data files for Burkina Faso\n",
      "Processing data files for Cabo Verde\n",
      "Processing data files for Cambodia\n",
      "Processing data files for Cameroon\n",
      "Processing data files for Canada\n",
      "Processing data files for Cape Verde\n",
      "Processing data files for Central African Republic\n",
      "Processing data files for Chad\n",
      "Processing data files for Chile\n",
      "Processing data files for China\n",
      "Processing data files for Colombia\n",
      "Processing data files for Congo (Brazzaville)\n",
      "Processing data files for Congo (Kinshasa)\n",
      "Processing data files for Costa Rica\n",
      "Processing data files for Cote d'Ivoire\n",
      "Processing data files for Croatia\n",
      "Processing data files for Cruise Ship\n",
      "Processing data files for Cuba\n",
      "Processing data files for Cyprus\n",
      "Processing data files for Czechia\n",
      "Processing data files for Denmark\n",
      "Processing data files for Djibouti\n",
      "Processing data files for Dominican Republic\n",
      "Processing data files for East Timor\n",
      "Processing data files for Ecuador\n",
      "Processing data files for Egypt\n",
      "Processing data files for El Salvador\n",
      "Processing data files for Equatorial Guinea\n",
      "Processing data files for Eritrea\n",
      "Processing data files for Estonia\n",
      "Processing data files for Eswatini\n",
      "Processing data files for Ethiopia\n",
      "Processing data files for Fiji\n",
      "Processing data files for Finland\n",
      "Processing data files for France\n",
      "Processing data files for Gabon\n",
      "Processing data files for Gambia, The\n",
      "Processing data files for Georgia\n",
      "Processing data files for Germany\n",
      "Processing data files for Ghana\n",
      "Processing data files for Greece\n",
      "Processing data files for Guatemala\n",
      "Processing data files for Guinea\n",
      "Processing data files for Guyana\n",
      "Processing data files for Haiti\n",
      "Processing data files for Holy See\n",
      "Processing data files for Honduras\n",
      "Processing data files for Hungary\n",
      "Processing data files for Iceland\n",
      "Processing data files for India\n",
      "Processing data files for Indonesia\n",
      "Processing data files for Iran\n",
      "Processing data files for Iraq\n",
      "Processing data files for Ireland\n",
      "Processing data files for Israel\n",
      "Processing data files for Italy\n",
      "Processing data files for Jamaica\n",
      "Processing data files for Japan\n",
      "Processing data files for Jordan\n",
      "Processing data files for Kazakhstan\n",
      "Processing data files for Kenya\n",
      "Processing data files for Korea, South\n",
      "Processing data files for Kosovo\n",
      "Processing data files for Kuwait\n",
      "Processing data files for Kyrgyzstan\n",
      "Processing data files for Latvia\n",
      "Processing data files for Lebanon\n",
      "Processing data files for Liberia\n",
      "Processing data files for Liechtenstein\n",
      "Processing data files for Lithuania\n",
      "Processing data files for Luxembourg\n",
      "Processing data files for Madagascar\n",
      "Processing data files for Malaysia\n",
      "Processing data files for Maldives\n",
      "Processing data files for Malta\n",
      "Processing data files for Martinique\n",
      "Processing data files for Mauritania\n",
      "Processing data files for Mauritius\n",
      "Processing data files for Mexico\n",
      "Processing data files for Moldova\n",
      "Processing data files for Monaco\n",
      "Processing data files for Mongolia\n",
      "Processing data files for Montenegro\n",
      "Processing data files for Morocco\n",
      "Processing data files for Namibia\n",
      "Processing data files for Nepal\n",
      "Processing data files for Netherlands\n",
      "Processing data files for New Zealand\n",
      "Processing data files for Nicaragua\n",
      "Processing data files for Niger\n",
      "Processing data files for Nigeria\n",
      "Processing data files for North Macedonia\n",
      "Processing data files for Norway\n",
      "Processing data files for Oman\n",
      "Processing data files for Pakistan\n",
      "Processing data files for Panama\n",
      "Processing data files for Papua New Guinea\n",
      "Processing data files for Paraguay\n",
      "Processing data files for Peru\n",
      "Processing data files for Philippines\n",
      "Processing data files for Poland\n",
      "Processing data files for Portugal\n",
      "Processing data files for Qatar\n",
      "Processing data files for Romania\n",
      "Processing data files for Russia\n",
      "Processing data files for Rwanda\n",
      "Processing data files for Saint Lucia\n",
      "Processing data files for Saint Vincent and the Grenadines\n",
      "Processing data files for San Marino\n",
      "Processing data files for Saudi Arabia\n",
      "Processing data files for Senegal\n",
      "Processing data files for Serbia\n",
      "Processing data files for Seychelles\n",
      "Processing data files for Singapore\n",
      "Processing data files for Slovakia\n",
      "Processing data files for Slovenia\n",
      "Processing data files for Somalia\n",
      "Processing data files for South Africa\n",
      "Processing data files for Spain\n",
      "Processing data files for Sri Lanka\n",
      "Processing data files for Sudan\n",
      "Processing data files for Suriname\n",
      "Processing data files for Sweden\n",
      "Processing data files for Switzerland\n",
      "Processing data files for Taiwan*\n",
      "Processing data files for Tanzania\n",
      "Processing data files for Thailand\n",
      "Processing data files for Togo\n",
      "Processing data files for Trinidad and Tobago\n",
      "Processing data files for Tunisia\n",
      "Processing data files for Turkey\n",
      "Processing data files for US\n",
      "['AK' 'AL' 'AR' 'AZ' 'CA' 'CO' 'CT' 'D.C.' 'DE' 'Diamond Princess' 'FL'\n",
      " 'GA' 'Grand Princess' 'Guam' 'HI' 'IA' 'ID' 'IL' 'IN' 'KS' 'KY' 'LA' 'MA'\n",
      " 'MD' 'ME' 'MI' 'MN' 'MO' 'MS' 'MT' 'NC' 'ND' 'NE' 'NH' 'NJ' 'NM' 'NV'\n",
      " 'NY' 'OH' 'OK' 'OR' 'PA' 'PR' 'RI' 'SC' 'SD' 'TN' 'TX' 'UT' 'VA' 'VI'\n",
      " 'VT' 'WA' 'WI' 'WV' 'WY']\n",
      "Processing data files for Uganda\n",
      "Processing data files for Ukraine\n",
      "Processing data files for United Arab Emirates\n",
      "Processing data files for United Kingdom\n",
      "Processing data files for Uruguay\n",
      "Processing data files for Uzbekistan\n",
      "Processing data files for Venezuela\n",
      "Processing data files for Vietnam\n",
      "Processing data files for Zambia\n",
      "Processing data files for Zimbabwe\n"
     ]
    }
   ],
   "source": [
    "countries = covid_19_national_observations['Country/Region'].unique()\n",
    "countries.sort()\n",
    "for cnt in countries:\n",
    "    partitionByCountry(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('miniconda3': virtualenv)",
   "language": "python",
   "name": "python37664bitminiconda3virtualenve3b6ad2979204d799798e97f12a748c5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
