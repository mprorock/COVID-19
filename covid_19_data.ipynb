{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./data/\"\n",
    "input_dir = \"./csse_covid_19_data/csse_covid_19_daily_reports/\"\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob(input_dir+'*.{}'.format(extension))]\n",
    "\n",
    "# %% combine em up\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "combined_csv.to_csv(output_dir + \"covid_19.csv\", index=False, encoding='utf-8-sig') \n",
    "\n",
    "# let's do a little data cleanup\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].str.strip()\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].replace('Korea, South', 'South Korea')\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].replace('Republic of Korea', 'South Korea')\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].replace('Iran (Islamic Republic of)', 'Iran')\n",
    "combined_csv['Country/Region'] = combined_csv['Country/Region'].replace('Mainland China', 'China')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_csv.copy()\n",
    "df['Last Update'] = pd.to_datetime(df['Last Update']).dt.date \n",
    "\n",
    "def firsti(Series, offset):\n",
    "    return Series.first(offset)\n",
    "\n",
    "df = df.groupby(by=['Last Update', 'Country/Region'])[\n",
    "    #'Last Update', 'Country/Region',\n",
    "    'Confirmed', 'Deaths', 'Recovered'].sum().reset_index()\n",
    "df = df.sort_values('Last Update', ascending=True).reset_index()\n",
    "df['Active Cases'] = df['Confirmed'] - df['Recovered'] - df['Deaths']\n",
    "df['Cases'] = df['Confirmed'] - df['Recovered'] \n",
    "df['Death Rate'] = df['Deaths'] / df['Confirmed']\n",
    "df['Recovery Rate'] = df['Recovered'] / df['Confirmed']\n",
    "df['New Deaths'] = df['Deaths'] - df['Deaths'].shift()\n",
    "df['New Recovered'] = df['Recovered'] - df['Recovered'].shift()\n",
    "df['New Cases'] = df['Confirmed'] - df['Confirmed'].shift()\n",
    "df['New Case Rate'] = df['New Cases'].pct_change()\n",
    "df['New Death Rate'] = df['New Deaths'].pct_change()\n",
    "df['Last Update'] = pd.to_datetime(df['Last Update'])\n",
    "df['Date'] = pd.DatetimeIndex(df['Last Update']).astype ( np.int64 )/1000000\n",
    "df['Day'] = df.groupby('Country/Region').cumcount()\n",
    "df = df.dropna().reset_index()\n",
    "\n",
    "df.to_csv(output_dir + \"covid_19_by_date_and_country.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallDf = df.copy().groupby('Last Update').agg({\n",
    "    'Confirmed':'sum',\n",
    "    'Deaths':'sum',\n",
    "    'Recovered':'sum'\n",
    "    }).reset_index()\n",
    "overallDf = overallDf.sort_values('Last Update', ascending=True)\n",
    "overallDf['Active Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] - overallDf['Deaths']\n",
    "overallDf['Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] \n",
    "overallDf['Death Rate'] = overallDf['Deaths'] / overallDf['Confirmed']\n",
    "overallDf['Recovery Rate'] = overallDf['Recovered'] / overallDf['Confirmed']\n",
    "overallDf['New Deaths'] = overallDf['Deaths'] - overallDf['Deaths'].shift()\n",
    "overallDf['New Recovered'] = overallDf['Recovered'] - overallDf['Recovered'].shift()\n",
    "overallDf['New Cases'] = overallDf['Confirmed'] - overallDf['Confirmed'].shift()\n",
    "overallDf['New Case Rate'] = overallDf['New Cases'].pct_change()\n",
    "overallDf['New Death Rate'] = overallDf['New Deaths'].pct_change()\n",
    "overallDf['Date'] = pd.DatetimeIndex(overallDf['Last Update']).astype ( np.int64 )/1000000\n",
    "overallDf = overallDf.dropna().reset_index()\n",
    "\n",
    "overallDf.to_csv(output_dir + \"covid_19_by_date.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallDf = df.copy().groupby('Day').agg({\n",
    "    'Confirmed':'sum',\n",
    "    'Deaths':'sum',\n",
    "    'Recovered':'sum'\n",
    "    }).reset_index()\n",
    "overallDf = overallDf.sort_values('Day', ascending=True)\n",
    "overallDf['Active Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] - overallDf['Deaths']\n",
    "overallDf['Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] \n",
    "overallDf['Death Rate'] = overallDf['Deaths'] / overallDf['Confirmed']\n",
    "overallDf['Recovery Rate'] = overallDf['Recovered'] / overallDf['Confirmed']\n",
    "overallDf['New Deaths'] = overallDf['Deaths'] - overallDf['Deaths'].shift()\n",
    "overallDf['New Recovered'] = overallDf['Recovered'] - overallDf['Recovered'].shift()\n",
    "overallDf['New Cases'] = overallDf['Confirmed'] - overallDf['Confirmed'].shift()\n",
    "overallDf['New Case Rate'] = overallDf['New Cases'].pct_change()\n",
    "overallDf['New Death Rate'] = overallDf['New Deaths'].pct_change()\n",
    "overallDf = overallDf.dropna().reset_index()\n",
    "\n",
    "overallDf.to_csv(output_dir + \"covid_19_by_day.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallDf = df.copy().groupby(by=['Country/Region','Day']).agg({\n",
    "    'Confirmed':'sum',\n",
    "    'Deaths':'sum',\n",
    "    'Recovered':'sum'\n",
    "    }).reset_index()\n",
    "overallDf = overallDf.sort_values('Day', ascending=True)\n",
    "overallDf['Active Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] - overallDf['Deaths']\n",
    "overallDf['Cases'] = overallDf['Confirmed'] - overallDf['Recovered'] \n",
    "overallDf['Death Rate'] = overallDf['Deaths'] / overallDf['Confirmed']\n",
    "overallDf['Recovery Rate'] = overallDf['Recovered'] / overallDf['Confirmed']\n",
    "overallDf['New Deaths'] = overallDf['Deaths'] - overallDf['Deaths'].shift()\n",
    "overallDf['New Recovered'] = overallDf['Recovered'] - overallDf['Recovered'].shift()\n",
    "overallDf['New Cases'] = overallDf['Confirmed'] - overallDf['Confirmed'].shift()\n",
    "overallDf['New Case Rate'] = overallDf['New Cases'].pct_change()\n",
    "overallDf['New Death Rate'] = overallDf['New Deaths'].pct_change()\n",
    "overallDf = overallDf.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#john's hopkins raw files\n",
    "ts_deaths = pd.read_csv('csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv')\n",
    "ts_recovered = pd.read_csv('csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv')\n",
    "ts_confirmed = pd.read_csv('csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv')\n",
    "\n",
    "# let's unpivot that nasty excel style stuff\n",
    "ts_deaths = pd.melt(ts_deaths, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name='Date', value_name='Observation')\n",
    "ts_deaths['Observation Type'] = 'Death'\n",
    "ts_recovered = pd.melt(ts_recovered, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name='Date', value_name='Observation')\n",
    "ts_recovered['Observation Type'] = 'Recovered'\n",
    "ts_confirmed = pd.melt(ts_confirmed, id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name='Date', value_name='Observation')\n",
    "ts_confirmed['Observation Type'] = 'Confirmed'\n",
    "\n",
    "ts_deaths['Date'] = pd.to_datetime(ts_deaths['Date'])\n",
    "ts_recovered['Date'] = pd.to_datetime(ts_recovered['Date'])\n",
    "ts_confirmed['Date'] = pd.to_datetime(ts_confirmed['Date'])\n",
    "\n",
    "#and concat into one nice set\n",
    "covid_19_ts = ts_deaths.copy()\n",
    "covid_19_ts = covid_19_ts.append(ts_recovered)\n",
    "covid_19_ts = covid_19_ts.append(ts_confirmed)\n",
    "covid_19_ts = covid_19_ts.sort_values(['Country/Region', 'Date']).reset_index(drop=True)\n",
    "#now drop 0 values\n",
    "covid_19_ts = covid_19_ts[covid_19_ts['Observation'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "overallDf.to_csv(output_dir + \"covid_19_by_date_and_country.csv\", index=False, encoding='utf-8-sig')\n",
    "covid_19_ts.to_csv(output_dir + \"covid_19_ts.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Observation</th>\n",
       "      <th>Observation Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>1</td>\n",
       "      <td>Confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>1</td>\n",
       "      <td>Confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>1</td>\n",
       "      <td>Confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>1</td>\n",
       "      <td>Confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>1</td>\n",
       "      <td>Confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78826</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>108.0000</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>16</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78827</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>108.0000</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>66</td>\n",
       "      <td>Confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78829</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>108.0000</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>16</td>\n",
       "      <td>Recovered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78830</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>108.0000</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>75</td>\n",
       "      <td>Confirmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>-15.4167</td>\n",
       "      <td>28.2833</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>2</td>\n",
       "      <td>Confirmed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11534 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Province/State Country/Region      Lat      Long       Date  \\\n",
       "101              NaN    Afghanistan  33.0000   65.0000 2020-02-24   \n",
       "104              NaN    Afghanistan  33.0000   65.0000 2020-02-25   \n",
       "107              NaN    Afghanistan  33.0000   65.0000 2020-02-26   \n",
       "110              NaN    Afghanistan  33.0000   65.0000 2020-02-27   \n",
       "113              NaN    Afghanistan  33.0000   65.0000 2020-02-28   \n",
       "...              ...            ...      ...       ...        ...   \n",
       "78826            NaN        Vietnam  16.0000  108.0000 2020-03-17   \n",
       "78827            NaN        Vietnam  16.0000  108.0000 2020-03-17   \n",
       "78829            NaN        Vietnam  16.0000  108.0000 2020-03-18   \n",
       "78830            NaN        Vietnam  16.0000  108.0000 2020-03-18   \n",
       "79001            NaN         Zambia -15.4167   28.2833 2020-03-18   \n",
       "\n",
       "       Observation Observation Type  \n",
       "101              1        Confirmed  \n",
       "104              1        Confirmed  \n",
       "107              1        Confirmed  \n",
       "110              1        Confirmed  \n",
       "113              1        Confirmed  \n",
       "...            ...              ...  \n",
       "78826           16        Recovered  \n",
       "78827           66        Confirmed  \n",
       "78829           16        Recovered  \n",
       "78830           75        Confirmed  \n",
       "79001            2        Confirmed  \n",
       "\n",
       "[11534 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display for debug\n",
    "display(covid_19_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run any JH combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_19_by_country_and_day_of_outbreak = pd.read_csv(output_dir + 'covid_19_by_date_and_country.csv')\n",
    "covid_19_by_date = pd.read_csv(output_dir + 'covid_19_by_date.csv')\n",
    "covid_19_by_day = pd.read_csv(output_dir + 'covid_19_by_day.csv')\n",
    "covid_19_overall = pd.read_csv(output_dir + 'covid_19.csv')\n",
    "covid_19_ts = pd.read_csv(output_dir + 'covid_19_ts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_19_ts['Date'] = pd.to_datetime(covid_19_ts['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = covid_19_ts.copy()\n",
    "#if you just want to include some, exclude others, see line below:\n",
    "#ts_df = covid_19_ts[covid_19_ts['Country/Region'] != 'US'].copy()\n",
    "ts_df = ts_df.drop('Province/State', axis=1)\n",
    "ts_df = ts_df.sort_values(['Country/Region', 'Date'])\n",
    "\n",
    "covid_19_national_observations = ts_df.groupby(['Date', 'Country/Region', 'Observation Type'])['Observation'].sum().reset_index()\n",
    "covid_19_national_observations = covid_19_national_observations.pivot_table(columns='Observation Type', index=['Date', 'Country/Region'], values='Observation').reset_index().rename_axis(None, axis=1).fillna(0)\n",
    "\n",
    "#let's get a copy for post infection as well\n",
    "covid_19_infected_observations = covid_19_national_observations.copy()\n",
    "covid_19_infected_observations = covid_19_infected_observations[covid_19_infected_observations['Confirmed'] >= 20].fillna(0)\n",
    "\n",
    "#on to key values for reporting\n",
    "covid_19_national_observations['Day'] = covid_19_national_observations.groupby('Country/Region')['Confirmed'].cumcount()\n",
    "covid_19_national_observations['Day'] = covid_19_national_observations.groupby('Country/Region')['Confirmed'].fillna(method='bfill')\n",
    "\n",
    "covid_19_national_observations['Active Cases'] = covid_19_national_observations['Confirmed'] - covid_19_national_observations['Recovered']  - covid_19_national_observations['Death'] \n",
    "\n",
    "covid_19_national_observations['Likely Cases 1pct'] = covid_19_national_observations['Death'] * 100\n",
    "covid_19_national_observations['Likely Cases 1.8pct'] = covid_19_national_observations['Death'] * 180\n",
    "covid_19_national_observations['Likely Cases 3.5pct'] = covid_19_national_observations['Death'] * 350\n",
    "\n",
    "covid_19_national_observations['Death Rate'] = np.round(covid_19_national_observations['Death'] / covid_19_national_observations['Confirmed'],3)\n",
    "covid_19_national_observations['Death Change Rate'] = covid_19_national_observations.groupby('Country/Region')['Death'].pct_change()\n",
    "covid_19_national_observations['Recovery Change Rate'] = covid_19_national_observations.groupby('Country/Region')['Recovered'].pct_change()\n",
    "covid_19_national_observations['Confirmed Change Rate'] = covid_19_national_observations.groupby('Country/Region')['Confirmed'].pct_change()\n",
    "\n",
    "#now for same values on limited set\n",
    "covid_19_infected_observations['Day'] = covid_19_infected_observations.groupby('Country/Region', squeeze=True).cumcount()\n",
    "\n",
    "covid_19_infected_observations['Active Cases'] = covid_19_infected_observations['Confirmed'] - covid_19_infected_observations['Recovered']  - covid_19_infected_observations['Death'] \n",
    "\n",
    "covid_19_infected_observations['Likely Cases 1pct'] = covid_19_infected_observations['Death'] * 100\n",
    "covid_19_infected_observations['Likely Cases 1.8pct'] = covid_19_infected_observations['Death'] * 180\n",
    "covid_19_infected_observations['Likely Cases 3.5pct'] = covid_19_infected_observations['Death'] * 350\n",
    "\n",
    "covid_19_infected_observations['Death Rate'] = np.round(covid_19_infected_observations['Death'] / covid_19_infected_observations['Confirmed'],3)\n",
    "covid_19_infected_observations['Death Change Rate'] = covid_19_infected_observations.groupby('Country/Region')['Death'].pct_change()\n",
    "covid_19_infected_observations['Recovery Change Rate'] = covid_19_infected_observations.groupby('Country/Region')['Recovered'].pct_change()\n",
    "covid_19_infected_observations['Confirmed Change Rate'] = covid_19_infected_observations.groupby('Country/Region')['Confirmed'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_19_national_observations.to_csv(output_dir + \"global/covid_19_national_observations.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "covid_19_infected_observations.to_csv(output_dir + \"global/covid_19_infected_observations.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Death</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Day</th>\n",
       "      <th>Active Cases</th>\n",
       "      <th>Likely Cases 1pct</th>\n",
       "      <th>Likely Cases 1.8pct</th>\n",
       "      <th>Likely Cases 3.5pct</th>\n",
       "      <th>Death Rate</th>\n",
       "      <th>Death Change Rate</th>\n",
       "      <th>Recovery Change Rate</th>\n",
       "      <th>Confirmed Change Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.225806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.072848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.234568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>321.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>372.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Country/Region  Confirmed  Death  Recovered    Day  \\\n",
       "856  2020-02-26         Brazil        1.0    0.0        0.0    1.0   \n",
       "903  2020-02-27         Brazil        1.0    0.0        0.0    1.0   \n",
       "955  2020-02-28         Brazil        1.0    0.0        0.0    1.0   \n",
       "1012 2020-02-29         Brazil        2.0    0.0        0.0    2.0   \n",
       "1075 2020-03-01         Brazil        2.0    0.0        0.0    2.0   \n",
       "1142 2020-03-02         Brazil        2.0    0.0        0.0    2.0   \n",
       "1216 2020-03-03         Brazil        2.0    0.0        0.0    2.0   \n",
       "1293 2020-03-04         Brazil        4.0    0.0        0.0    4.0   \n",
       "1375 2020-03-05         Brazil        4.0    0.0        0.0    4.0   \n",
       "1460 2020-03-06         Brazil       13.0    0.0        0.0   13.0   \n",
       "1553 2020-03-07         Brazil       13.0    0.0        0.0   13.0   \n",
       "1649 2020-03-08         Brazil       20.0    0.0        0.0   20.0   \n",
       "1750 2020-03-09         Brazil       25.0    0.0        0.0   25.0   \n",
       "1853 2020-03-10         Brazil       31.0    0.0        0.0   31.0   \n",
       "1960 2020-03-11         Brazil       38.0    0.0        0.0   38.0   \n",
       "2072 2020-03-12         Brazil       52.0    0.0        0.0   52.0   \n",
       "2187 2020-03-13         Brazil      151.0    0.0        0.0  151.0   \n",
       "2307 2020-03-14         Brazil      151.0    0.0        0.0  151.0   \n",
       "2441 2020-03-15         Brazil      162.0    0.0        0.0  162.0   \n",
       "2581 2020-03-16         Brazil      200.0    0.0        1.0  200.0   \n",
       "2727 2020-03-17         Brazil      321.0    1.0        2.0  321.0   \n",
       "2875 2020-03-18         Brazil      372.0    3.0        2.0  372.0   \n",
       "\n",
       "      Active Cases  Likely Cases 1pct  Likely Cases 1.8pct  \\\n",
       "856            1.0                0.0                  0.0   \n",
       "903            1.0                0.0                  0.0   \n",
       "955            1.0                0.0                  0.0   \n",
       "1012           2.0                0.0                  0.0   \n",
       "1075           2.0                0.0                  0.0   \n",
       "1142           2.0                0.0                  0.0   \n",
       "1216           2.0                0.0                  0.0   \n",
       "1293           4.0                0.0                  0.0   \n",
       "1375           4.0                0.0                  0.0   \n",
       "1460          13.0                0.0                  0.0   \n",
       "1553          13.0                0.0                  0.0   \n",
       "1649          20.0                0.0                  0.0   \n",
       "1750          25.0                0.0                  0.0   \n",
       "1853          31.0                0.0                  0.0   \n",
       "1960          38.0                0.0                  0.0   \n",
       "2072          52.0                0.0                  0.0   \n",
       "2187         151.0                0.0                  0.0   \n",
       "2307         151.0                0.0                  0.0   \n",
       "2441         162.0                0.0                  0.0   \n",
       "2581         199.0                0.0                  0.0   \n",
       "2727         318.0              100.0                180.0   \n",
       "2875         367.0              300.0                540.0   \n",
       "\n",
       "      Likely Cases 3.5pct  Death Rate  Death Change Rate  \\\n",
       "856                   0.0       0.000                NaN   \n",
       "903                   0.0       0.000                NaN   \n",
       "955                   0.0       0.000                NaN   \n",
       "1012                  0.0       0.000                NaN   \n",
       "1075                  0.0       0.000                NaN   \n",
       "1142                  0.0       0.000                NaN   \n",
       "1216                  0.0       0.000                NaN   \n",
       "1293                  0.0       0.000                NaN   \n",
       "1375                  0.0       0.000                NaN   \n",
       "1460                  0.0       0.000                NaN   \n",
       "1553                  0.0       0.000                NaN   \n",
       "1649                  0.0       0.000                NaN   \n",
       "1750                  0.0       0.000                NaN   \n",
       "1853                  0.0       0.000                NaN   \n",
       "1960                  0.0       0.000                NaN   \n",
       "2072                  0.0       0.000                NaN   \n",
       "2187                  0.0       0.000                NaN   \n",
       "2307                  0.0       0.000                NaN   \n",
       "2441                  0.0       0.000                NaN   \n",
       "2581                  0.0       0.000                NaN   \n",
       "2727                350.0       0.003                inf   \n",
       "2875               1050.0       0.008                2.0   \n",
       "\n",
       "      Recovery Change Rate  Confirmed Change Rate  \n",
       "856                    NaN                    NaN  \n",
       "903                    NaN               0.000000  \n",
       "955                    NaN               0.000000  \n",
       "1012                   NaN               1.000000  \n",
       "1075                   NaN               0.000000  \n",
       "1142                   NaN               0.000000  \n",
       "1216                   NaN               0.000000  \n",
       "1293                   NaN               1.000000  \n",
       "1375                   NaN               0.000000  \n",
       "1460                   NaN               2.250000  \n",
       "1553                   NaN               0.000000  \n",
       "1649                   NaN               0.538462  \n",
       "1750                   NaN               0.250000  \n",
       "1853                   NaN               0.240000  \n",
       "1960                   NaN               0.225806  \n",
       "2072                   NaN               0.368421  \n",
       "2187                   NaN               1.903846  \n",
       "2307                   NaN               0.000000  \n",
       "2441                   NaN               0.072848  \n",
       "2581                   inf               0.234568  \n",
       "2727                   1.0               0.605000  \n",
       "2875                   0.0               0.158879  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_19_national_observations[covid_19_national_observations['Country/Region']=='Brazil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_totals = covid_19_national_observations.groupby(['Date']).sum().reset_index().copy()\n",
    "world_totals = world_totals.sort_values('Date')\n",
    "world_totals['Total Confirmed'] = world_totals['Confirmed'].rolling(1).sum()\n",
    "world_totals['Total Deaths'] = world_totals['Death'].rolling(1).sum()\n",
    "world_totals['Total Recovered'] = world_totals['Recovered'].rolling(1).sum()\n",
    "world_totals['Active Cases'] = world_totals['Total Confirmed'] - world_totals['Total Deaths'] - world_totals['Total Recovered']\n",
    "world_totals['Death Rate'] = np.round(world_totals['Total Deaths'] / world_totals['Total Confirmed'],3)\n",
    "world_totals['Death Change Rate'] = world_totals['Total Deaths'].pct_change()\n",
    "world_totals['Recovery Change Rate'] = world_totals['Total Recovered'].pct_change()\n",
    "world_totals['Confirmed Change Rate'] = world_totals['Total Confirmed'].pct_change()\n",
    "\n",
    "world_totals['Likely Cases C86'] = world_totals['Active Cases'] * 1.14\n",
    "world_totals['Likely Cases 1pct'] = world_totals['Total Deaths'] * 100\n",
    "world_totals['Likely Cases 1.8pct'] = world_totals['Total Deaths'] * 180\n",
    "world_totals['Likely Cases 3.5pct'] = world_totals['Total Deaths'] * 350\n",
    "\n",
    "world_totals.to_csv(output_dir + \"global/covid_19_world_totals.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country specific stuff below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitionByCountry(country):  \n",
    "    print('Processing data files for', country)\n",
    "    c = country.lower().replace(' ', '_')\n",
    "    c = c.replace('*', '').replace('(', '_').replace(')', '_')\n",
    "    os.makedirs(output_dir + 'countries/'+c, exist_ok=True)\n",
    "\n",
    "    df = covid_19_ts[covid_19_ts['Country/Region'] == country].copy()\n",
    "    df = df.sort_values(['Province/State', 'Date'])\n",
    "\n",
    "    cases = pd.DataFrame()\n",
    "    if df['Province/State'].count() == 0:\n",
    "        df['Province/State'] = country\n",
    "        cases = df.groupby(['Date', 'Observation Type'])['Observation'].sum().reset_index()\n",
    "        cases = cases.pivot_table(columns='Observation Type', index=['Date'], values='Observation').reset_index().rename_axis(None, axis=1)\n",
    "        cases['Province/State'] = country\n",
    "    else:\n",
    "        cases = df.groupby(['Date', 'Province/State', 'Observation Type'])['Observation'].sum().reset_index()\n",
    "        cases = cases.pivot_table(columns='Observation Type', index=['Date', 'Province/State'], values='Observation').reset_index().rename_axis(None, axis=1)\n",
    "    \n",
    "    # check if columns exist\n",
    "    if 'Death' not in cases.columns:\n",
    "        cases['Death'] = 0\n",
    "    if 'Confirmed' not in cases.columns:\n",
    "        cases['Death'] = 0\n",
    "    if 'Recovered' not in cases.columns:\n",
    "        cases['Recovered'] = 0\n",
    "    \n",
    "    totals = cases.groupby(['Date']).sum().reset_index().copy()\n",
    "    totals = totals.sort_values('Date')    \n",
    "    \n",
    "    totals['Total Confirmed'] = totals['Confirmed'].rolling(1).sum()\n",
    "    totals['Total Deaths'] = totals['Death'].rolling(1).sum()\n",
    "    totals['Total Recovered'] = totals['Recovered'].rolling(1).sum()\n",
    "    totals['Active Cases'] = totals['Total Confirmed'] - totals['Total Deaths'] - totals['Total Recovered']\n",
    "    totals['Death Rate'] = np.round(totals['Total Deaths'] / totals['Total Confirmed'], 3)\n",
    "    totals['Death Change Rate'] = np.round(totals['Total Deaths'].pct_change(), 3)\n",
    "    totals['Recovery Change Rate'] = np.round(totals['Total Recovered'].pct_change(), 3)\n",
    "    totals['Confirmed Change Rate'] = np.round(totals['Total Confirmed'].pct_change(), 3)\n",
    "    \n",
    "    totals['Likely Cases C86'] = totals['Active Cases'] * 1.14\n",
    "    totals['Likely Cases 1pct'] = totals['Total Deaths'] * 100\n",
    "    totals['Likely Cases 1.8pct'] = totals['Total Deaths'] * 180\n",
    "    totals['Likely Cases 3.5pct'] = totals['Total Deaths'] * 350\n",
    "    \n",
    "    if df['Province/State'].count() <= 1:\n",
    "        cases['Total Confirmed'] = cases['Confirmed'].rolling(1).sum()\n",
    "        cases['Total Deaths'] = cases['Death'].rolling(1).sum()\n",
    "        cases['Total Recovered'] = cases['Recovered'].rolling(1).sum()\n",
    "    else:\n",
    "        cases['Total Confirmed'] = cases.groupby('Province/State')['Confirmed'].rolling(1).sum().reset_index(0,drop=True)\n",
    "        cases['Total Deaths'] = cases.groupby('Province/State')['Death'].rolling(1).sum().reset_index(0,drop=True)\n",
    "        cases['Total Recovered'] = cases.groupby('Province/State')['Recovered'].rolling(1).sum().reset_index(0,drop=True)\n",
    "    cases['Active Cases'] = totals['Total Confirmed'] - totals['Total Deaths'] - totals['Total Recovered']\n",
    "    cases['Death Rate'] = np.round(totals['Total Deaths'] / totals['Total Confirmed'],3)\n",
    "    cases['Death Change Rate'] = np.round(totals['Total Deaths'].pct_change(), 3)\n",
    "    cases['Recovery Change Rate'] = np.round(totals['Total Recovered'].pct_change(), 3)\n",
    "    cases['Confirmed Change Rate'] = np.round(totals['Total Confirmed'].pct_change(), 3)\n",
    "\n",
    "    \n",
    "    cases['Likely Cases 1pct'] = np.round(cases['Death'] * 100)\n",
    "    cases['Likely Cases 1.8pct'] = np.round(cases['Death'] * 180)\n",
    "    cases['Likely Cases 3.5pct'] = np.round(cases['Death'] * 350)\n",
    "    cases['Likely Cases C86'] = np.round(cases['Confirmed'] * 1.14)\n",
    "\n",
    "    \n",
    "    if c == 'us':\n",
    "        states_abbrv=pd.read_csv('./reference/US-state-abbrv.csv')\n",
    "        states=pd.DataFrame()\n",
    "        states['Province/State'] = cases['Province/State'].drop_duplicates().str.rsplit(',').str[-1].str.strip()\n",
    "        states_abbrv['Abbreviation'] = states_abbrv['Abbreviation'].str.strip()\n",
    "        states_abbrv['State'] = states_abbrv['State'].str.strip()\n",
    "        states = pd.merge(left=states, right=states_abbrv, left_on='Province/State', right_on='Abbreviation', how='left')\n",
    "        states['State'] = states['State'].fillna(states['Province/State'])\n",
    "        \n",
    "        states.to_csv(output_dir + \"countries/us/state_list.csv\", index=False)\n",
    "    \n",
    "    cases.to_csv(output_dir + 'countries/'+c+'/covid_19_'+c+'_cases.csv', index=False, encoding='utf-8-sig')\n",
    "    totals.to_csv(output_dir + 'countries/'+c+'/covid_19_'+c+'_totals.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data files for China\n",
      "Processing data files for Japan\n",
      "Processing data files for Korea, South\n",
      "Processing data files for Taiwan*\n",
      "Processing data files for Thailand\n",
      "Processing data files for US\n",
      "Processing data files for Singapore\n",
      "Processing data files for Vietnam\n",
      "Processing data files for France\n",
      "Processing data files for Malaysia\n",
      "Processing data files for Nepal\n",
      "Processing data files for Australia\n",
      "Processing data files for Canada\n",
      "Processing data files for Cambodia\n",
      "Processing data files for Germany\n",
      "Processing data files for Sri Lanka\n",
      "Processing data files for Finland\n",
      "Processing data files for United Arab Emirates\n",
      "Processing data files for India\n",
      "Processing data files for Philippines\n",
      "Processing data files for Italy\n",
      "Processing data files for Russia\n",
      "Processing data files for Sweden\n",
      "Processing data files for United Kingdom\n",
      "Processing data files for Spain\n",
      "Processing data files for Belgium\n",
      "Processing data files for Cruise Ship\n",
      "Processing data files for Egypt\n",
      "Processing data files for Iran\n",
      "Processing data files for Israel\n",
      "Processing data files for Lebanon\n",
      "Processing data files for Afghanistan\n",
      "Processing data files for Bahrain\n",
      "Processing data files for Iraq\n",
      "Processing data files for Kuwait\n",
      "Processing data files for Oman\n",
      "Processing data files for Algeria\n",
      "Processing data files for Austria\n",
      "Processing data files for Croatia\n",
      "Processing data files for Switzerland\n",
      "Processing data files for Brazil\n",
      "Processing data files for Georgia\n",
      "Processing data files for Greece\n",
      "Processing data files for North Macedonia\n",
      "Processing data files for Norway\n",
      "Processing data files for Pakistan\n",
      "Processing data files for Romania\n",
      "Processing data files for Denmark\n",
      "Processing data files for Estonia\n",
      "Processing data files for Netherlands\n",
      "Processing data files for San Marino\n",
      "Processing data files for Belarus\n",
      "Processing data files for Iceland\n",
      "Processing data files for Lithuania\n",
      "Processing data files for Mexico\n",
      "Processing data files for New Zealand\n",
      "Processing data files for Nigeria\n",
      "Processing data files for Ireland\n",
      "Processing data files for Luxembourg\n",
      "Processing data files for Monaco\n",
      "Processing data files for Qatar\n",
      "Processing data files for Armenia\n",
      "Processing data files for Azerbaijan\n",
      "Processing data files for Czechia\n",
      "Processing data files for Dominican Republic\n",
      "Processing data files for Ecuador\n",
      "Processing data files for Andorra\n",
      "Processing data files for Indonesia\n",
      "Processing data files for Latvia\n",
      "Processing data files for Morocco\n",
      "Processing data files for Portugal\n",
      "Processing data files for Saudi Arabia\n",
      "Processing data files for Senegal\n",
      "Processing data files for Argentina\n",
      "Processing data files for Chile\n",
      "Processing data files for Jordan\n",
      "Processing data files for Ukraine\n",
      "Processing data files for Hungary\n",
      "Processing data files for Liechtenstein\n",
      "Processing data files for Poland\n",
      "Processing data files for Tunisia\n",
      "Processing data files for Bosnia and Herzegovina\n",
      "Processing data files for Slovenia\n",
      "Processing data files for South Africa\n",
      "Processing data files for Bhutan\n",
      "Processing data files for Cameroon\n",
      "Processing data files for Colombia\n",
      "Processing data files for Costa Rica\n",
      "Processing data files for Holy See\n",
      "Processing data files for Peru\n",
      "Processing data files for Serbia\n",
      "Processing data files for Slovakia\n",
      "Processing data files for Togo\n",
      "Processing data files for Malta\n",
      "Processing data files for Martinique\n",
      "Processing data files for Bangladesh\n",
      "Processing data files for Bulgaria\n",
      "Processing data files for Maldives\n",
      "Processing data files for Moldova\n",
      "Processing data files for Paraguay\n",
      "Processing data files for Albania\n",
      "Processing data files for Brunei\n",
      "Processing data files for Cyprus\n",
      "Processing data files for Burkina Faso\n",
      "Processing data files for Mongolia\n",
      "Processing data files for Panama\n",
      "Processing data files for Bolivia\n",
      "Processing data files for Congo (Kinshasa)\n",
      "Processing data files for Cote d'Ivoire\n",
      "Processing data files for Honduras\n",
      "Processing data files for Jamaica\n",
      "Processing data files for Turkey\n",
      "Processing data files for Cuba\n",
      "Processing data files for Guyana\n",
      "Processing data files for Antigua and Barbuda\n",
      "Processing data files for Ethiopia\n",
      "Processing data files for Guinea\n",
      "Processing data files for Kazakhstan\n",
      "Processing data files for Kenya\n",
      "Processing data files for Sudan\n",
      "Processing data files for Eswatini\n",
      "Processing data files for Gabon\n",
      "Processing data files for Ghana\n",
      "Processing data files for Guatemala\n",
      "Processing data files for Mauritania\n",
      "Processing data files for Namibia\n",
      "Processing data files for Rwanda\n",
      "Processing data files for Saint Lucia\n",
      "Processing data files for Saint Vincent and the Grenadines\n",
      "Processing data files for Seychelles\n",
      "Processing data files for Suriname\n",
      "Processing data files for Trinidad and Tobago\n",
      "Processing data files for Uruguay\n",
      "Processing data files for Venezuela\n",
      "Processing data files for Central African Republic\n",
      "Processing data files for Congo (Brazzaville)\n",
      "Processing data files for Equatorial Guinea\n",
      "Processing data files for Kosovo\n",
      "Processing data files for Uzbekistan\n",
      "Processing data files for Benin\n",
      "Processing data files for Greenland\n",
      "Processing data files for Liberia\n",
      "Processing data files for Somalia\n",
      "Processing data files for Tanzania\n",
      "Processing data files for The Bahamas\n",
      "Processing data files for Barbados\n",
      "Processing data files for Gambia, The\n",
      "Processing data files for Montenegro\n",
      "Processing data files for Djibouti\n",
      "Processing data files for Kyrgyzstan\n",
      "Processing data files for Mauritius\n",
      "Processing data files for Zambia\n"
     ]
    }
   ],
   "source": [
    "countries = covid_19_national_observations['Country/Region'].unique()\n",
    "for cnt in countries:\n",
    "    partitionByCountry(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('miniconda3': virtualenv)",
   "language": "python",
   "name": "python37664bitminiconda3virtualenve3b6ad2979204d799798e97f12a748c5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
